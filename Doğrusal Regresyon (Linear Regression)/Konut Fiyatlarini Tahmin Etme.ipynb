{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Modüllerin eklenmesi\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "degerlendirme_tablosu = pd.DataFrame({'Model': [],\n",
    "                           'Detaylar':[],\n",
    "                           'Root Mean Squared Error (RMSE)':[],\n",
    "                           'R-squared (eğitim)':[],\n",
    "                           'Adjusted R-squared (eğitim)':[],\n",
    "                           'R-squared (test)':[],\n",
    "                           'Adjusted R-squared (test)':[],\n",
    "                           '5-Fold Cross Validation':[]})\n",
    "\n",
    "df = pd.read_csv('../datasets/kc_house_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusted $R^{2}$ Hesaplama Fonksiyonunu Tanımlama\n",
    "\n",
    "Özellik sayısı arttıkça R-squared'da artar. Bundan dolayı, iki farklı modelin performansı karşılaştırmak için daha sağlam bir değerlendirici tercih edilir. Bu değerlendiriciye Adjusted $R^{2}$ denir ve yalnızca değişkenin eklenmesi MSE'yi azaltırsa artar.\n",
    "\n",
    "Adjusted $R^{2}:$\n",
    "\n",
    "$$\\bar{R^{2}}=R^{2}-\\frac{k-1}{n-k}(1-R^{2})$$\n",
    "\n",
    "* n : gözlem sayısıdır.\n",
    "* k : parametre sayısıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustedR2(r2,n,k):\n",
    "    return r2-(k-1)/(n-k)*(1-r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basit Doğrusal Regresyon Oluşturma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir cevap ve sadece bir açıklayıcı değişken arasındaki doğrusal bir ilişkiyi modellediğimizde buna basit doğrusal regresyon denir. Konut fiyatlarını tahmin etmeye çalıştığımız için cevap değişkenimiz fiyattır(price). Basit bir model için bir tane özellik seçmemiz gerekir. Correlation matrisine baktığımız da fiyat ile ilişkili en iyi değişkenin sqft_living olduğunu görürüz. Bu sebeple özellik olarak sqft_living seçiyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()[\"price\"].sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "train_data,test_data = train_test_split(df,train_size = 0.8,random_state=3) # veri setimizi,eğitim seti ve test seti olarak 2'ye bölüyoruz.\n",
    "\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "\n",
    "X_train = np.array(train_data['sqft_living'], dtype=pd.Series).reshape(-1,1) # özellik olarak sqft_living seçiyoruz ve X_train değişkenine atıyoruz.\n",
    "y_train = np.array(train_data['price'], dtype=pd.Series) # hedef değer(yada cevap değer) olarak price seçiyoruz ve y_train değişkenine atıyoruz.\n",
    "lin_reg.fit(X_train,y_train) # basit doğrusal regresyon modelimizi fit(uydurma) ediyoruz.\n",
    "\n",
    "# test verisinde sqft_living özelliğini(açıklayıcı özellik) ve price özelliğini(cevap özellik) ayırıyoruz:\n",
    "X_test = np.array(test_data['sqft_living'], dtype=pd.Series).reshape(-1,1) \n",
    "y_test = np.array(test_data['price'], dtype=pd.Series)\n",
    "\n",
    "tahmin = lin_reg.predict(X_test) # test setindeki sqft_living özelliğini kullanarak,\n",
    "                                 # oluşturduğumuz basit doğrusal regresyon modeline tahminler yaptırıyoruz.\n",
    "\n",
    "rmsesm = float(format(np.sqrt(metrics.mean_squared_error(y_test,tahmin)),'.3f')) # mean squared error(ortalama kare hatası) hesaplıyoruz.\n",
    "rtrsm = float(format(lin_reg.score(X_train, y_train),'.3f')) # modelin eğitim setindeki skorunu hesaplıyoruz.\n",
    "rtesm = float(format(lin_reg.score(X_test, y_test),'.3f')) # modelin test setindeki skorunu hesaplıyoruz.\n",
    "cv = float(format(cross_val_score(lin_reg,df[['sqft_living']],df['price'],cv=5).mean(),'.3f')) # cross validation(çapraz değerlendirme) yaparak \n",
    "                                                                                               # modelimizi değerlendiriyoruz.\n",
    "    \n",
    "print (\"Test Setinde Ortalama Fiyat: {:.3f}\".format(y_test.mean()))\n",
    "print('Intercept(modelin y eksenini kestiği nokta): {}'.format(lin_reg.intercept_))\n",
    "print('Coefficient(sqft_living özelliğinin katsayısı): {}'.format(lin_reg.coef_))\n",
    "\n",
    "r = degerlendirme_tablosu.shape[0]\n",
    "degerlendirme_tablosu.loc[r] = ['Basit Doğrusal Regresyon','-',rmsesm,rtrsm,'-',rtesm,'-',cv]\n",
    "degerlendirme_tablosu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonuca Bakalım\n",
    "\n",
    "Modelimiz çok iyi uymuş(fit) gibi görünmüyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.5,5))\n",
    "plt.scatter(X_test,y_test,color='blue',label=\"Data\", alpha=.1)\n",
    "plt.plot(X_test,lin_reg.predict(X_test),color=\"red\",label=\"Regresyon Tahmin Çizgisi\")\n",
    "plt.xlabel(\"Yaşam Alanı (sqft)\", fontsize=15)\n",
    "plt.ylabel(\"Fiyat ($)\", fontsize=15)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verileri Görselleştirme ve İnceleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir model geliştirmeden önce grafik çizmek ve verileri incelemek çok faydalıdır,çünkü bazı olası aykırı değerleri tespit edebilir veya normalleştirmeye yapmaya karar verebiliriz. Bu bir zorunluluk değildir ancak verilerinizin her zaman iyi olduğunu bilmelisiniz. Dataframe'in histogramını çizerek başlayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "df1=df[['price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
    "    'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "    'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
    "    'lat', 'long', 'sqft_living15', 'sqft_lot15']]\n",
    "h = df1.hist(bins=25,figsize=(16,16),xlabelsize='10',ylabelsize='10',xrot=-15)\n",
    "sns.despine(left=True, bottom=True)\n",
    "[x.title.set_size(12) for x in h.ravel()];\n",
    "[x.yaxis.tick_left() for x in h.ravel()];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşağıdaki grafiklerden, 33 yatak odası veya 7000000 civarında fiyat gibi diğerlerinden çok uzak bazı özelliklere veya fiyatlara sahip çok az sayıda ev olduğu görülebilir. Ancak, olası olumsuz etkilerinin belirlenmesi zaman alıcı ve gerçek veri setlerinde olacaktır. Bu veri kümesinde her zaman bazı lüks ev fiyatları gibi bazı aykırı değerler olacaktır. Bu yüzden aykırı değerleri kaldırmayı düşünmüyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", font_scale=1)\n",
    "f, axes = plt.subplots(1, 2,figsize=(15,5))\n",
    "sns.boxplot(x=df['bedrooms'],y=df['price'], ax=axes[0])\n",
    "sns.boxplot(x=df['floors'],y=df['price'], ax=axes[1])\n",
    "sns.despine(left=True, bottom=True)\n",
    "axes[0].set(xlabel='Bedrooms - yatak odaları', ylabel='Price')\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[1].yaxis.set_label_position(\"right\")\n",
    "axes[1].yaxis.tick_right()\n",
    "axes[1].set(xlabel='Floors - katlar', ylabel='Price')\n",
    "\n",
    "f, axe = plt.subplots(1, 1,figsize=(12.18,5))\n",
    "sns.despine(left=True, bottom=True)\n",
    "sns.boxplot(x=df['bathrooms'],y=df['price'], ax=axe)\n",
    "axe.yaxis.tick_left()\n",
    "axe.set(xlabel='Banyo / Yatak Odası', ylabel='Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yukarıdaki grafiklerden de görüldüğü gibi, yukarıda kullandığımız özellikler ile fiyat arasında mükemmel bir doğrusal ilişki yok.Peki diğer özellikler ile arasındaki ilişki? Bunu görstermek için 3D grafikler kullanalım. Nokta rengi olarak açık yeşil kullanılmıştır. Koyu yeşil kısımlar yüksek yoğunluk anlamına gelir,birçok açık yeşil nokta çakışır ve koyulaşır.\n",
    "\n",
    "Aşağıdaki grafikler sqrt_living arttıkça,sqrt_lot ve bedrooms veya bathromms/bedrooms özelliklerinin de arttığını gösteriyor. Ancak floors,bedrooms ve bathrooms/bedrooms veya sqrt_living  benzer ilişkiye sahip değiller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(19,12.5))\n",
    "ax=fig.add_subplot(2,2,1, projection=\"3d\")\n",
    "ax.scatter(df['floors'],df['bedrooms'],df['bathrooms'],c=\"darkgreen\",alpha=.5)\n",
    "ax.set(xlabel='\\nFloors',ylabel='\\nBedrooms',zlabel='\\nBathrooms / Bedrooms')\n",
    "ax.set(ylim=[0,12])\n",
    "\n",
    "ax=fig.add_subplot(2,2,2, projection=\"3d\")\n",
    "ax.scatter(df['floors'],df['bedrooms'],df['sqft_living'],c=\"darkgreen\",alpha=.5)\n",
    "ax.set(xlabel='\\nFloors',ylabel='\\nBedrooms',zlabel='\\nsqft Living')\n",
    "ax.set(ylim=[0,12])\n",
    "\n",
    "ax=fig.add_subplot(2,2,3, projection=\"3d\")\n",
    "ax.scatter(df['sqft_living'],df['sqft_lot'],df['bathrooms'],c=\"darkgreen\",alpha=.5)\n",
    "ax.set(xlabel='\\n sqft Living',ylabel='\\nsqft Lot',zlabel='\\nBathrooms / Bedrooms')\n",
    "ax.set(ylim=[0,250000])\n",
    "\n",
    "ax=fig.add_subplot(2,2,4, projection=\"3d\")\n",
    "ax.scatter(df['sqft_living'],df['sqft_lot'],df['bedrooms'],c=\"darkgreen\",alpha=.5)\n",
    "ax.set(xlabel='\\n sqft Living',ylabel='\\nsqft Lot',zlabel='Bedrooms')\n",
    "ax.set(ylim=[0,250000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daha fazla özelliği görselleştirelim. Aşağıdaki boxplot lara baktığımızda grade ve waterfront özelliğinin price özelliğini etkilediği açıkça görülebiliyor. Diğer tarafran view özelliği daha az etkilidir ancak yine de fiyat üzerinde etkisi vardır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2,figsize=(15,5))\n",
    "sns.boxplot(x=df['waterfront'],y=df['price'], ax=axes[0])\n",
    "sns.boxplot(x=df['view'],y=df['price'], ax=axes[1])\n",
    "sns.despine(left=True, bottom=True)\n",
    "axes[0].set(xlabel='Waterfront', ylabel='Price')\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[1].yaxis.set_label_position(\"right\")\n",
    "axes[1].yaxis.tick_right()\n",
    "axes[1].set(xlabel='View', ylabel='Price')\n",
    "\n",
    "f, axe = plt.subplots(1, 1,figsize=(12.18,5))\n",
    "sns.boxplot(x=df['grade'],y=df['price'], ax=axe)\n",
    "sns.despine(left=True, bottom=True)\n",
    "axe.yaxis.tick_left()\n",
    "axe.set(xlabel='Grade', ylabel='Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view,grade ve year built arasındaki ilişkiyi belirlemek için 3D grafik çizdirelim. Aşağıdaki grafik, yeni evlerin daha iyi grade özelliği olduğunu ancak view özelliğindeki değişiklik hakkında çok fazla şey söyleyemeyeceğimizi gösteriyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(9.5,6.25))\n",
    "ax=fig.add_subplot(1,1,1, projection=\"3d\")\n",
    "ax.scatter(train_data['view'],train_data['grade'],train_data['yr_built'],c=\"darkgreen\",alpha=.5)\n",
    "ax.set(xlabel='\\nView',ylabel='\\nGrade',zlabel='\\nYear Built');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Açıklayıcı Değişkenler Arasındaki Korelasyonun Gözden Geçirilmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir modelde çok fazla özelliğe sahip olmak her zaman iyi bir şey değildir çünkü aşırı uymaya(overfitting) ve yeni veri seti için değerler tahmin etmek istediğimizde kötü sonuçlar almamıza neden olabilir. Bu nedenle, bir özellik eğer modelinizi çok geliştirmiyorsa o özelliği eklememek daha iyidir.\n",
    "\n",
    "Önemli olan başka bir şey de korelasyondur. İki özellik arasında yüksek korelasyon varsa, aşırı uymaya(overfitting) neden olmaması için o iki özelliğide tutmak çoğu zaman iyi bir fikir değildir. Örneğin, eğer aşırı uyma(overfitting) varsa,sqt_above veya sqt_living özelliğini kaldırabiliriz çünkü bu iki özellik yüksek korelasyonludur.Bu ilişki veri kümesindeki tanımlara baktığımızda tahmin edilebilir, ancak yine de korelasyon matrisi kontrol edilmelidir.Bununla birlikte, bu, yüksek derecede ilişkili özelliklerden birini kaldırmanız gerektiği anlamına gelmez. Örneğin:bathrooms ve sqrt_living. Bu iki özellik yüksek derecede ilişkilidirler(correlated) ancak aralarındaki ilişkinin sqt_living ve sqt_above arasındaki ilişki ile aynı olduğunu düşünmüyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "features = ['price','bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n",
    "            'view','condition','grade','sqft_above','sqft_basement','yr_built','yr_renovated',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "\n",
    "mask = np.zeros_like(df[features].corr(), dtype=np.bool) \n",
    "mask[np.triu_indices_from(mask)] = True \n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 12))\n",
    "plt.title('Pearson Correlation Matrix',fontsize=25)\n",
    "\n",
    "sns.heatmap(df[features].corr(),linewidths=0.25,vmax=0.7,square=True,cmap=\"BuGn\", #\"BuGn_r\" to reverse \n",
    "            linecolor='w',annot=True,annot_kws={\"size\":8},mask=mask,cbar_kws={\"shrink\": .9});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri Önişleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriler üzerinde ön işleme yapmak modelin doğruluğunu arttırabilir ve modeli daha güvenli hale getirir. Bu işlem her zaman sonuçlarımızı geliştirmez,iyileştirmez ama özelliklerin farkında olduğumuzda, özelliklerin bilincinde olduğumuzda ve uygun bir girdi kullandığımızda, bazı sonuçlara daha kolay ulaşabiliriz.Dönüşüm veya normalizasyon gibi çeşitli veri madenciliği tekniklerini denenmiştir ama sonunda, sadece binning kullanılmaya karar verilmiştir ve df_dm adlı yeni bir dataframe oluşturulmuştur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dm=df.copy()\n",
    "df_dm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning - Gruplama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri gruplaması, küçük gözlem hatalarının etkilerini azaltmak için kullanılan bir ön işleme tekniğidir. Bu veri setinde bazı sütünlara uygulamaya değerdir. Gruplama yr_built ve yr_renovated özelliğine uygulanmıştır. Evlerin yaşları ve satıldıklarındaki onarım yaşları eklenmiştir. Ayrıca, bu sütunlar aralıklara ayrılmıştır ve bunu aşağıdaki histogramda görebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# sadece yıl özelliğini alıyoruz\n",
    "df_dm['sales_yr']=df_dm['date'].astype(str).str[:4]\n",
    "\n",
    "# Konut satıldığındaki yaşını yeni bir sütun olarak ekliyoruz\n",
    "df_dm['age']=df_dm['sales_yr'].astype(int)-df_dm['yr_built']\n",
    "\n",
    "# Konut satıldığındaki yenileme yaşını yeni bir sütun olarak ekliyoruz.\n",
    "df_dm['age_rnv']=0\n",
    "df_dm['age_rnv']=df_dm['sales_yr'][df_dm['yr_renovated']!=0].astype(int)-df_dm['yr_renovated'][df_dm['yr_renovated']!=0]\n",
    "df_dm['age_rnv'][df_dm['age_rnv'].isnull()]=0\n",
    "\n",
    "# yaşı bölümlere ayırıyoruz.\n",
    "bins = [-2,0,5,10,25,50,75,100,100000]\n",
    "labels = ['<1','1-5','6-10','11-25','26-50','51-75','76-100','>100']\n",
    "df_dm['age_binned'] = pd.cut(df_dm['age'], bins=bins, labels=labels)\n",
    "\n",
    "# age_rnv özelliğini bölümlere ayırıyoruz.\n",
    "bins = [-2,0,5,10,25,50,75,100000]\n",
    "labels = ['<1','1-5','6-10','11-25','26-50','51-75','>75']\n",
    "df_dm['age_rnv_binned'] = pd.cut(df_dm['age_rnv'], bins=bins, labels=labels)\n",
    "\n",
    "# bölümlere ayrılan sütunların histogramı\n",
    "f, axes = plt.subplots(1, 2,figsize=(15,5))\n",
    "p1=sns.countplot(df_dm['age_binned'],ax=axes[0])\n",
    "for p in p1.patches:\n",
    "    height = p.get_height()\n",
    "    p1.text(p.get_x()+p.get_width()/2,height + 50,height,ha=\"center\")   \n",
    "p2=sns.countplot(df_dm['age_rnv_binned'],ax=axes[1])\n",
    "sns.despine(left=True, bottom=True)\n",
    "for p in p2.patches:\n",
    "    height = p.get_height()\n",
    "    p2.text(p.get_x()+p.get_width()/2,height + 200,height,ha=\"center\")\n",
    "    \n",
    "axes[0].set(xlabel='Age')\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[1].yaxis.set_label_position(\"right\")\n",
    "axes[1].yaxis.tick_right()\n",
    "axes[1].set(xlabel='Renovation Age');\n",
    "\n",
    "# modelde kullanabilmek için faktör değerlerini dönüştürmek\n",
    "df_dm = pd.get_dummies(df_dm, columns=['age_binned','age_rnv_binned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Çoklu Regresyon (Multiple Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İlk başta basit doğrusal regresyon kullandık ancak zayıf bir uyum(fit) elde ettik. Bu modeli geliştirmek için daha fazla özellik ekleyelim. Doğrusal Regresyonda birden fazla özellik olduğunda buna çoklu regresyon denir. O zaman şimdi daha karmaşık modeller oluşturalım:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Çoklu Regresyon - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İlk önce özellikler önceki bölümlere bakılarak belirlenmiştir ve ilk çoklu doğrusal regresyonda kullanılmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# veri seti ,eğitim setine ve test setine bölünüyor\n",
    "train_data_dm,test_data_dm = train_test_split(df_dm,train_size = 0.8,random_state=3)\n",
    "\n",
    "\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','zipcode'] #özelliklerin seçimi\n",
    "complex_model_1 = linear_model.LinearRegression() \n",
    "complex_model_1.fit(train_data_dm[features],train_data_dm['price']) #çoklu regresyon oluşturma\n",
    "\n",
    "\n",
    "pred = complex_model_1.predict(test_data_dm[features]) # oluşturulan model kullanılarak tahminlerin yapılması\n",
    "\n",
    "# hataların hesaplanması\n",
    "rmsecm = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred)),'.3f'))\n",
    "rtrcm = float(format(complex_model_1.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm = float(format(adjustedR2(complex_model_1.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm = float(format(complex_model_1.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm = float(format(adjustedR2(complex_model_1.score(test_data_dm[features],test_data['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "# cross validation kullanılarak modelin değerlendirilmesi\n",
    "cv = float(format(cross_val_score(complex_model_1,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = degerlendirme_tablosu.shape[0]\n",
    "degerlendirme_tablosu.loc[r] = ['Çoklu Regresyon-1','seçili özellikler',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\n",
    "degerlendirme_tablosu.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Çoklu Regresyon - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Önceki çoklu regresyona ek olarak özellikler listesine daha fazla özellik eklenmiştir. Değerlendirme metriklerine bakıldığında,model önemli ölçüde geliştiğimtir,iyileşmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# özellik seçimi\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view',\n",
    "             'grade','age_binned_<1', 'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', \n",
    "             'age_binned_26-50', 'age_binned_51-75','age_binned_76-100', 'age_binned_>100',\n",
    "             'zipcode']\n",
    "\n",
    "# model oluşturma\n",
    "complex_model_2 = linear_model.LinearRegression()\n",
    "complex_model_2.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "\n",
    "\n",
    "pred = complex_model_2.predict(test_data_dm[features]) #tahminler\n",
    "\n",
    "# hataların hesaplanması\n",
    "rmsecm = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred)),'.3f'))\n",
    "rtrcm = float(format(complex_model_2.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm = float(format(adjustedR2(complex_model_2.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm = float(format(complex_model_2.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm = float(format(adjustedR2(complex_model_2.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz doğrulama kullanılarak modelin değerlendirilmesi\n",
    "cv = float(format(cross_val_score(complex_model_2,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = degerlendirme_tablosu.shape[0]\n",
    "degerlendirme_tablosu.loc[r] = ['Çoklu Regresyon-2','seçili özellikler',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\n",
    "degerlendirme_tablosu.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Çoklu Regresyon - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Farklılıkları kolayca gözlemlemek için, herhangi bir ön işleme yapmadan tüm özelliklere sahip bir model oluşturulmuştur. Değerlendirme metrikleri yine dikkat çekici şekilde iyileşti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# özellik seçimi\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view',\n",
    "            'condition','grade','sqft_above','sqft_basement','yr_built','yr_renovated',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "\n",
    "# model oluşturma\n",
    "complex_model_3 = linear_model.LinearRegression()\n",
    "complex_model_3.fit(train_data[features],train_data['price'])\n",
    "\n",
    "\n",
    "pred = complex_model_3.predict(test_data[features]) #tahminler\n",
    "\n",
    "# hataların hesaplanması\n",
    "rmsecm = float(format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred)),'.3f'))\n",
    "rtrcm = float(format(complex_model_3.score(train_data[features],train_data['price']),'.3f'))\n",
    "artrcm = float(format(adjustedR2(complex_model_3.score(train_data[features],train_data['price']),train_data.shape[0],len(features)),'.3f'))\n",
    "rtecm = float(format(complex_model_3.score(test_data[features],test_data['price']),'.3f'))\n",
    "artecm = float(format(adjustedR2(complex_model_3.score(test_data[features],test_data['price']),test_data.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz doğrulama kullanarak modelin değerlendirilmesi\n",
    "\n",
    "cv = float(format(cross_val_score(complex_model_3,df[features],df['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = degerlendirme_tablosu.shape[0]\n",
    "degerlendirme_tablosu.loc[r] = ['Çoklu Regresyon-3','tüm özellikler, ön işleme yok',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\n",
    "degerlendirme_tablosu.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Çoklu Regresyon - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu kez ön işleme adımından sonra elde edilen veriler kullanılmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# özellik seçimi\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n",
    "            'view','condition','grade','sqft_above','sqft_basement','age_binned_<1', \n",
    "            'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', 'age_binned_26-50',\n",
    "            'age_binned_51-75','age_binned_76-100', 'age_binned_>100','age_rnv_binned_<1',\n",
    "            'age_rnv_binned_1-5', 'age_rnv_binned_6-10', 'age_rnv_binned_11-25',\n",
    "            'age_rnv_binned_26-50', 'age_rnv_binned_51-75', 'age_rnv_binned_>75',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "\n",
    "#model oluşturma\n",
    "complex_model_4 = linear_model.LinearRegression()\n",
    "complex_model_4.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "\n",
    "pred = complex_model_4.predict(test_data_dm[features]) #tahminlerin yapılması\n",
    "\n",
    "#hataların hesaplanması\n",
    "rmsecm = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred)),'.3f'))\n",
    "rtrcm = float(format(complex_model_4.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm = float(format(adjustedR2(complex_model_4.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm = float(format(complex_model_4.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm = float(format(adjustedR2(complex_model_4.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz değerlendirme kullanılarak modelin değerlendirilmesi\n",
    "cv = float(format(cross_val_score(complex_model_4,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = degerlendirme_tablosu.shape[0]\n",
    "degerlendirme_tablosu.loc[r] = ['Çoklu Regresyon-4','tüm özellikler',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\n",
    "degerlendirme_tablosu.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Düzenlileştirme (Regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Düzenlileştirme,aşırı uyma(overfitting) ve eksik öğrenme(underfitting) sorununu çözmek için tasarlanmıştır. Aşırı uymanın(overfitting) anlamı yüksek varyans ve karmaşık modeldir ve bu durumda genellikle eğitim verileri iyi uyulur(fit) ancak test verilerinde kötü sonuçlar elde edilmesine neden olabilir. Eksik öğrenme ise düşük varyans ve basit modeldir. Bu da kötü sonuçlara neden olabilir. Olası çözümler özellikleri manuel olarak ayarlamak veya ekstra iş yükü getiren bazı model seçim algoritmaları kullanmaktır. Bunun aksine,düzenlileştirmeyi uyguladığımızda tüm özellikler korunur ve model $\\theta_{j}$'yi ayarlar. Bu,özellikle çok az kullanışlı özelliğimiz olduğunda işe yarar. Ridge Regresyon,Lasso Regresyon ve Elastic Net düzenlileştirmesini kullanacağız.\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "<b>Ridge Regresyon,Lasso Regresyon ve Elastic Net ne zaman kullanılır?</b>\n",
    "\n",
    "* En azından biraz düzenlileştirme olması neredeyse her zaman tercih edilir bu sebeple düz Doğrusal Regresyondan kaçınmalısınız.\n",
    "* Ridge iyi bir varsayılandır ancak eğer sadece birkaç özelliğin faydalı,işe yarar olduğunu düşünüyorsanız Lasso veya Elastic Net tercih etmelisiniz çünkü Lasso ve Elastic Net faydasız,işe yaramaz özelliklerin ağırlıklarını sıfır yapma eğilimindedir.\n",
    "* Genel olarak Lasso'ya karşı Elastic Net tercih edilir çünkü Lasso, özellik sayısı eğitim örneği sayısından daha fazla olduğunda veya birkaç özellik güçlü bir şekilde ilişkili(correlated) olduğunda düzensiz davranabilir.\n",
    "* Birçok küçük / orta boyutlu etkiye sahip değişken varsa: Ridge kullanılabilir.\n",
    "* Orta / büyük etkiye sahip sadece birkaç değişken varsa: Lasso kullanılabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regresyon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regresyona L2 düzenlileştirmesi de denir ve bir ceza terimi ekleyerek aşağıdaki denklemi elde ederiz:\n",
    "\n",
    "$$RSS_{RIDGE} = \\sum_{i=1}^{m}(h_{\\theta}(x_{i})-y_{i})^{2} + \\alpha \\sum_{j=1}^{n}\\theta^{2}_{j}$$\n",
    "\n",
    "$\\alpha$ değerini değiştirerek düzenlileştirme miktarını kontrol edebiliriz.Eğer $\\alpha=0$ ise, Ridge Regresyon bir Doğrusal Regresyon olur. Eğer $\\theta$ çok büyük ise tüm ağırlıklar sıfıra çok yakın olacaktır.\n",
    "\n",
    "Aşağıda farklı $\\alpha$ değerleri kullanılarak farklı Ridge Regresyon modelli eğitilmiştir ve sonuçlar değerlendirme tablosuna eklenmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# özellik seçimi\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n",
    "            'view','condition','grade','sqft_above','sqft_basement','age_binned_<1', \n",
    "            'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', 'age_binned_26-50',\n",
    "            'age_binned_51-75','age_binned_76-100', 'age_binned_>100','age_rnv_binned_<1',\n",
    "            'age_rnv_binned_1-5', 'age_rnv_binned_6-10', 'age_rnv_binned_11-25',\n",
    "            'age_rnv_binned_26-50', 'age_rnv_binned_51-75', 'age_rnv_binned_>75',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "\n",
    "# alpha =1 ile model oluşturulması\n",
    "complex_model_R = linear_model.Ridge(alpha=1)\n",
    "complex_model_R.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred1 = complex_model_R.predict(test_data_dm[features]) # tahminlerin alınması\n",
    "\n",
    "#hataların hesaplanması\n",
    "rmsecm1 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred1)),'.3f'))\n",
    "rtrcm1 = float(format(complex_model_R.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm1 = float(format(adjustedR2(complex_model_R.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm1 = float(format(complex_model_R.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm1 = float(format(adjustedR2(complex_model_R.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz değerlendirme kullanarak modelin değerlendirilmesi\n",
    "cv1 = float(format(cross_val_score(complex_model_R,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "# alpha =100 ile Ridge Regresyon oluşturulması\n",
    "complex_model_R = linear_model.Ridge(alpha=100)\n",
    "complex_model_R.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred2 = complex_model_R.predict(test_data_dm[features]) #tahminlerin hesaplanması\n",
    "\n",
    "#hataların hesaplanması\n",
    "rmsecm2 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred2)),'.3f'))\n",
    "rtrcm2 = float(format(complex_model_R.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm2 = float(format(adjustedR2(complex_model_R.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm2 = float(format(complex_model_R.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm2 = float(format(adjustedR2(complex_model_R.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz doğrulama kullanarak modelin değerlendirilmesi\n",
    "cv2 = float(format(cross_val_score(complex_model_R,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "#alpha=1000 ile Ridge Regresyon modelinin oluşturulması\n",
    "complex_model_R = linear_model.Ridge(alpha=1000)\n",
    "complex_model_R.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred3 = complex_model_R.predict(test_data_dm[features]) #tahminlerin hesaplanması\n",
    "\n",
    "# hataların hesaplanması\n",
    "rmsecm3 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred3)),'.3f'))\n",
    "rtrcm3 = float(format(complex_model_R.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm3 = float(format(adjustedR2(complex_model_R.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm3 = float(format(complex_model_R.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm3 = float(format(adjustedR2(complex_model_R.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz doğrulama kullanarak modelin değerlendirilmesi\n",
    "cv3 = float(format(cross_val_score(complex_model_R,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "\n",
    "#sonuçların değerlendirme tablosuna eklenmesi\n",
    "r = degerlendirme_tablosu.shape[0]\n",
    "degerlendirme_tablosu.loc[r] = ['Ridge Regresyon','alpha=1, tüm özellikler',rmsecm1,rtrcm1,artrcm1,rtecm1,artecm1,cv1]\n",
    "degerlendirme_tablosu.loc[r+1] = ['Ridge Regresyon','alpha=100, tüm özellikler',rmsecm2,rtrcm2,artrcm2,rtecm2,artecm2,cv2]\n",
    "degerlendirme_tablosu.loc[r+2] = ['Ridge Regresyon','alpha=1000, tüm özellikler',rmsecm3,rtrcm3,artrcm3,rtecm3,artecm3,cv3]\n",
    "degerlendirme_tablosu.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regresyon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regresyona L1 düzenlileştirilmesi de denir ve aşağıdaki gibi tanımlanır:\n",
    "\n",
    "$$RSS_{LASSO} = \\sum_{i=1}^{m}(h_{\\theta}(x_{i})-y_{i})^{2} + \\alpha \\sum_{j=1}^{n}|\\theta_{j}|$$\n",
    "\n",
    "Ridge Regresyon ile Lasso Regresyon arasındaki temel fark ceza terimidir. $\\alpha$ değerinin görevi aynıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# özellik seçimi\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n",
    "            'view','condition','grade','sqft_above','sqft_basement','age_binned_<1', \n",
    "            'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', 'age_binned_26-50',\n",
    "            'age_binned_51-75','age_binned_76-100', 'age_binned_>100','age_rnv_binned_<1',\n",
    "            'age_rnv_binned_1-5', 'age_rnv_binned_6-10', 'age_rnv_binned_11-25',\n",
    "            'age_rnv_binned_26-50', 'age_rnv_binned_51-75', 'age_rnv_binned_>75',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "\n",
    "# alpha=1 ile Lasso Regresyon modeli oluşturma\n",
    "complex_model_L = linear_model.Lasso(alpha=1)\n",
    "complex_model_L.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred1 = complex_model_L.predict(test_data_dm[features]) #tahminlerin hesaplanması\n",
    "\n",
    "#hataların hesaplanması\n",
    "rmsecm1 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred1)),'.3f'))\n",
    "rtrcm1 = float(format(complex_model_L.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm1 = float(format(adjustedR2(complex_model_L.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm1 = float(format(complex_model_L.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm1 = float(format(adjustedR2(complex_model_L.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz doğrulama kullanarak modelin değerlendirilmesi\n",
    "cv1 = float(format(cross_val_score(complex_model_L,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "#alpha=100 ile Lasso Regresyon modelinin oluşturulması\n",
    "complex_model_L = linear_model.Lasso(alpha=100)\n",
    "complex_model_L.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred2 = complex_model_L.predict(test_data_dm[features]) #tahminlerin yapılması\n",
    "\n",
    "#hataların hesaplanması\n",
    "rmsecm2 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred2)),'.3f'))\n",
    "rtrcm2 = float(format(complex_model_L.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm2 = float(format(adjustedR2(complex_model_L.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm2 = float(format(complex_model_L.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm2 = float(format(adjustedR2(complex_model_L.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz doğrulama kullanarak modelin değerlendirilmesi\n",
    "cv2 = float(format(cross_val_score(complex_model_L,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "# alpha=1000 ile Lasso Regresyon modelinin oluşturulması\n",
    "complex_model_L = linear_model.Lasso(alpha=1000)\n",
    "complex_model_L.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred3 = complex_model_L.predict(test_data_dm[features]) #tahminlerin yapılması\n",
    "\n",
    "#hataların hesaplanması\n",
    "rmsecm3 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred3)),'.3f'))\n",
    "rtrcm3 = float(format(complex_model_L.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm3 = float(format(adjustedR2(complex_model_L.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm3 = float(format(complex_model_L.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm3 = float(format(adjustedR2(complex_model_L.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz doğrulama kullanarak modelin değerlendirilmesi\n",
    "cv3 = float(format(cross_val_score(complex_model_L,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "#sonuçların değerlendirme tablosuna eklenmesi\n",
    "r = degerlendirme_tablosu.shape[0]\n",
    "degerlendirme_tablosu.loc[r] = ['Lasso Regresyon','alpha=1, tüm özellikler',rmsecm1,rtrcm1,artrcm1,rtecm1,artecm1,cv1]\n",
    "degerlendirme_tablosu.loc[r+1] = ['Lasso Regresyon','alpha=100, tüm özellikler',rmsecm2,rtrcm2,artrcm2,rtecm2,artecm2,cv2]\n",
    "degerlendirme_tablosu.loc[r+2] = ['Lasso Regresyon','alpha=1000, tüm özellikler',rmsecm3,rtrcm3,artrcm3,rtecm3,artecm3,cv3]\n",
    "degerlendirme_tablosu.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net\n",
    "\n",
    "Elastic Net, Ridge Regresyon ile Lasso Regresyonun ortasındadır. Elastic Net'in maliyet fonksiyonu Ridge Regresyonun maliyet fonksiyonu ile Lasso Regresyonun maliyet fonksiyonunun karışımıdır ve bu karışımı,r hiperparametresini kullanarak kontrol edebilirsiniz. r=0 olduğunda Elastic Net, Ridge Regresyona denktir ve r=1 olduğunda Elastic Net, Lasso Regresyona denktir.\n",
    "\n",
    "Elastic Net Maliyet Fonksiyonu:\n",
    "\n",
    "$$J(\\theta)=MSE(\\theta)+r \\alpha \\sum_{i=1}^n |\\theta_{i}|+\\frac{1-r}{2} \\alpha \\sum_{i=1}^{n} \\theta_{i}^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# özellik seçimi\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n",
    "            'view','condition','grade','sqft_above','sqft_basement','age_binned_<1', \n",
    "            'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', 'age_binned_26-50',\n",
    "            'age_binned_51-75','age_binned_76-100', 'age_binned_>100','age_rnv_binned_<1',\n",
    "            'age_rnv_binned_1-5', 'age_rnv_binned_6-10', 'age_rnv_binned_11-25',\n",
    "            'age_rnv_binned_26-50', 'age_rnv_binned_51-75', 'age_rnv_binned_>75',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "\n",
    "# alpha=1 ve l1_ratio=0.5 ile Elastic Net Regresyon modeli oluşturma\n",
    "complex_model_E = linear_model.ElasticNet(alpha=1,l1_ratio=0.5)\n",
    "complex_model_E.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred1 = complex_model_E.predict(test_data_dm[features]) #tahminlerin hesaplanması\n",
    "\n",
    "#hataların hesaplanması\n",
    "rmsecm1 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred1)),'.3f'))\n",
    "rtrcm1 = float(format(complex_model_E.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm1 = float(format(adjustedR2(complex_model_E.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm1 = float(format(complex_model_E.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm1 = float(format(adjustedR2(complex_model_E.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz doğrulama kullanarak modelin değerlendirilmesi\n",
    "cv1 = float(format(cross_val_score(complex_model_E,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "#alpha=100 ve l1_ratio=0.5 ile Elastic Net Regresyon modelinin oluşturulması\n",
    "complex_model_E = linear_model.ElasticNet(alpha=100,l1_ratio=0.5)\n",
    "complex_model_E.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred2 = complex_model_E.predict(test_data_dm[features]) #tahminlerin yapılması\n",
    "\n",
    "#hataların hesaplanması\n",
    "rmsecm2 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred2)),'.3f'))\n",
    "rtrcm2 = float(format(complex_model_E.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm2 = float(format(adjustedR2(complex_model_E.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm2 = float(format(complex_model_E.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm2 = float(format(adjustedR2(complex_model_E.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz doğrulama kullanarak modelin değerlendirilmesi\n",
    "cv2 = float(format(cross_val_score(complex_model_E,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "# alpha=1000 l1_ratio=0.5 ile Elastic Net Regresyon modelinin oluşturulması\n",
    "complex_model_E = linear_model.ElasticNet(alpha=1000,l1_ratio=0.5)\n",
    "complex_model_E.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred3 = complex_model_E.predict(test_data_dm[features]) #tahminlerin yapılması\n",
    "\n",
    "#hataların hesaplanması\n",
    "rmsecm3 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred3)),'.3f'))\n",
    "rtrcm3 = float(format(complex_model_E.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm3 = float(format(adjustedR2(complex_model_E.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm3 = float(format(complex_model_E.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm3 = float(format(adjustedR2(complex_model_E.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "\n",
    "#çapraz doğrulama kullanarak modelin değerlendirilmesi\n",
    "cv3 = float(format(cross_val_score(complex_model_E,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "#sonuçların değerlendirme tablosuna eklenmesi\n",
    "r = degerlendirme_tablosu.shape[0]\n",
    "degerlendirme_tablosu.loc[r] = ['Elastic Net Regresyon','alpha=1 ve l1_ratio=0.5, tüm özellikler',rmsecm1,rtrcm1,artrcm1,rtecm1,artecm1,cv1]\n",
    "degerlendirme_tablosu.loc[r+1] = ['Elastic Net Regresyon','alpha=100 ve l1_ratio=0.5, tüm özellikler',rmsecm2,rtrcm2,artrcm2,rtecm2,artecm2,cv2]\n",
    "degerlendirme_tablosu.loc[r+2] = ['Elastic Net Regresyon','alpha=1000 ve l1_ratio=0.5, tüm özellikler',rmsecm3,rtrcm3,artrcm3,rtecm3,artecm3,cv3]\n",
    "degerlendirme_tablosu.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polinom Regresyon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doğrusal modeller için ana fikir verilerimize düz bir çizgi uydurmaktır(fit). Ancak veriler ikinci dereceden dağılıma sahipse, ikinci dereceden bir fonksiyon seçmek ve bir polinom dönüşüşümü uygulamak bize daha iyi sonuçlar verebilir.Bu kez hipotez fonksiyonu şu şekilde tanımlanır:\n",
    "\n",
    "$$h_{\\theta}(X)=\\theta_{0}+\\theta_{1}x+\\theta_{2}x^{2}+...+\\theta_{n}x^{n}$$\n",
    "\n",
    "Polinom Regresyonu için çok çeşitlilik olduğu için,sonuçları yeni bir tablo ile göstermek tercih edilmiştir ve aşağıdaki tabloda polinom dönüşümünün modelin aşırı uymasını(overfitting) iyileştirdiği görülebilir. Öte yanda, polinom dönüşümü kullanırken ve dereceye karar verirken dikkatli olmalıyız çünkü aşırı uymaya(overfitting) neden olabilir. Ayrıca,aşağıdaki tabloda bazı modeller için aşırı uyma(overfitting) vardır. 5-fold cross validation metrikleri,eğitim seti için çok yüksek R kare değerlerine sahip olmalarına rağmen bu modeller için(aşırı uymuş(overfitting) modeller için) negatif veya düşüktür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "evaluation_poly = pd.DataFrame({'Model': [],\n",
    "                                'Detaylar':[],\n",
    "                                'Root Mean Squared Error (RMSE)':[],\n",
    "                                'R-squared (eğitim)':[],\n",
    "                                'Adjusted R-squared (eğitim)':[],\n",
    "                                'R-squared (test)':[],\n",
    "                                'Adjusted R-squared (test)':[],\n",
    "                                '5-Fold Cross Validation':[]})\n",
    "\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view',\n",
    "             'grade','yr_built','zipcode']\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data[features])\n",
    "poly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred1 = poly.predict(X_testpoly)\n",
    "rmsepoly1 = float(format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred1)),'.3f'))\n",
    "rtrpoly1 = float(format(poly.score(X_trainpoly,train_data['price']),'.3f'))\n",
    "rtepoly1 = float(format(poly.score(X_testpoly,test_data['price']),'.3f'))\n",
    "cv1 = float(format(cross_val_score(linear_model.LinearRegression(),X_allpoly,df['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=3)\n",
    "X_allpoly = polyfeat.fit_transform(df[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data[features])\n",
    "poly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred2 = poly.predict(X_testpoly)\n",
    "rmsepoly2 = float(format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred2)),'.3f'))\n",
    "rtrpoly2 = float(format(poly.score(X_trainpoly,train_data['price']),'.3f'))\n",
    "rtepoly2 = float(format(poly.score(X_testpoly,test_data['price']),'.3f'))\n",
    "cv2 = float(format(cross_val_score(linear_model.LinearRegression(),X_allpoly,df['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view',\n",
    "            'condition','grade','sqft_above','sqft_basement','yr_built','yr_renovated',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data[features])\n",
    "poly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred3 = poly.predict(X_testpoly)\n",
    "rmsepoly3 = float(format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred3)),'.3f'))\n",
    "rtrpoly3 = float(format(poly.score(X_trainpoly,train_data['price']),'.3f'))\n",
    "rtepoly3 = float(format(poly.score(X_testpoly,test_data['price']),'.3f'))\n",
    "cv3 = float(format(cross_val_score(linear_model.LinearRegression(),X_allpoly,df['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=3)\n",
    "X_allpoly = polyfeat.fit_transform(df[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data[features])\n",
    "poly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred4 = poly.predict(X_testpoly)\n",
    "rmsepoly4 = float(format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred4)),'.3f'))\n",
    "rtrpoly4 = float(format(poly.score(X_trainpoly,train_data['price']),'.3f'))\n",
    "rtepoly4 = float(format(poly.score(X_testpoly,test_data['price']),'.3f'))\n",
    "cv4 = float(format(cross_val_score(linear_model.LinearRegression(),X_allpoly,df['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n",
    "            'view','condition','grade','sqft_above','sqft_basement','age_binned_<1', \n",
    "            'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', 'age_binned_26-50',\n",
    "            'age_binned_51-75','age_binned_76-100', 'age_binned_>100','age_rnv_binned_<1',\n",
    "            'age_rnv_binned_1-5', 'age_rnv_binned_6-10', 'age_rnv_binned_11-25',\n",
    "            'age_rnv_binned_26-50', 'age_rnv_binned_51-75', 'age_rnv_binned_>75',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df_dm[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data_dm[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data_dm[features])\n",
    "poly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred5 = poly.predict(X_testpoly)\n",
    "rmsepoly5 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred5)),'.3f'))\n",
    "rtrpoly5 = float(format(poly.score(X_trainpoly,train_data_dm['price']),'.3f'))\n",
    "rtepoly5 = float(format(poly.score(X_testpoly,test_data_dm['price']),'.3f'))\n",
    "cv5 = float(format(cross_val_score(linear_model.LinearRegression(),X_allpoly,df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df_dm[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data_dm[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data_dm[features])\n",
    "poly = linear_model.Ridge(alpha=1).fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred6 = poly.predict(X_testpoly)\n",
    "rmsepoly6 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred6)),'.3f'))\n",
    "rtrpoly6 = float(format(poly.score(X_trainpoly,train_data_dm['price']),'.3f'))\n",
    "rtepoly6 = float(format(poly.score(X_testpoly,test_data_dm['price']),'.3f'))\n",
    "cv6 = float(format(cross_val_score(linear_model.Ridge(alpha=1),X_allpoly,df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df_dm[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data_dm[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data_dm[features])\n",
    "poly = linear_model.Ridge(alpha=50000).fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred7 = poly.predict(X_testpoly)\n",
    "rmsepoly7 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred7)),'.3f'))\n",
    "rtrpoly7 = float(format(poly.score(X_trainpoly,train_data_dm['price']),'.3f'))\n",
    "rtepoly7 = float(format(poly.score(X_testpoly,test_data_dm['price']),'.3f'))\n",
    "cv7 = float(format(cross_val_score(linear_model.Ridge(alpha=50000),X_allpoly,df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df_dm[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data_dm[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data_dm[features])\n",
    "poly = linear_model.Lasso(alpha=1).fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred8 = poly.predict(X_testpoly)\n",
    "rmsepoly8 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred8)),'.3f'))\n",
    "rtrpoly8 = float(format(poly.score(X_trainpoly,train_data_dm['price']),'.3f'))\n",
    "rtepoly8 = float(format(poly.score(X_testpoly,test_data_dm['price']),'.3f'))\n",
    "cv8 = float(format(cross_val_score(linear_model.Lasso(alpha=1),X_allpoly,df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df_dm[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data_dm[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data_dm[features])\n",
    "poly = linear_model.Lasso(alpha=50000).fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred9 = poly.predict(X_testpoly)\n",
    "rmsepoly9 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred9)),'.3f'))\n",
    "rtrpoly9 = float(format(poly.score(X_trainpoly,train_data_dm['price']),'.3f'))\n",
    "rtepoly9 = float(format(poly.score(X_testpoly,test_data_dm['price']),'.3f'))\n",
    "cv9 = float(format(cross_val_score(linear_model.Lasso(alpha=50000),X_allpoly,df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = evaluation_poly.shape[0]\n",
    "evaluation_poly.loc[r] = ['Polynomial Regression','degree=2, selected features, no preprocessing',rmsepoly1,rtrpoly1,'-',rtepoly1,'-',cv1]\n",
    "evaluation_poly.loc[r+1] = ['Polynomial Regression','degree=3, selected features, no preprocessing',rmsepoly2,rtrpoly2,'-',rtepoly2,'-',cv2]\n",
    "evaluation_poly.loc[r+2] = ['Polynomial Regression','degree=2, all features, no preprocessing',rmsepoly3,rtrpoly3,'-',rtepoly3,'-',cv3]\n",
    "evaluation_poly.loc[r+3] = ['Polynomial Regression','degree=3, all features, no preprocessing',rmsepoly4,rtrpoly4,'-',rtepoly4,'-',cv4]\n",
    "evaluation_poly.loc[r+4] = ['Polynomial Regression','degree=2, all features',rmsepoly5,rtrpoly5,'-',rtepoly5,'-',cv5]\n",
    "evaluation_poly.loc[r+5] = ['Polynomial Ridge Regression','alpha=1, degree=2, all features',rmsepoly6,rtrpoly6,'-',rtepoly6,'-',cv6]\n",
    "evaluation_poly.loc[r+6] = ['Polynomial Ridge Regression','alpha=50000, degree=2, all features',rmsepoly7,rtrpoly7,'-',rtepoly7,'-',cv7]\n",
    "evaluation_poly.loc[r+7] = ['Polynomial Lasso Regression','alpha=1, degree=2, all features',rmsepoly8,rtrpoly8,'-',rtepoly8,'-',cv8]\n",
    "evaluation_poly.loc[r+8] = ['Polynomial Lasso Regression','alpha=50000, degree=2, all features',rmsepoly9,rtrpoly9,'-',rtepoly9,'-',cv9]\n",
    "evaluation_poly_temp = evaluation_poly[['Model','Details','Root Mean Squared Error (RMSE)','R-squared (training)','R-squared (test)','5-Fold Cross Validation']]\n",
    "evaluation_poly_temp.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Değerlendirme Tablosu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "degerlendirme_tablosu_temp=degerlendirme_tablosu.append(evaluation_poly)\n",
    "degerlendirme_tablosu_temp1=degerlendirme_tablosu_temp.sort_values(by = '5-Fold Cross Validation', ascending=False)\n",
    "degerlendirme_tablosu_temp2=degerlendirme_tablosu_temp1.reset_index()\n",
    "degerlendirme_tablosu_f=degerlendirme_tablosu_temp2.iloc[:,1:]\n",
    "degerlendirme_tablosu_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Çalışırken Türkeleştirmeye çalıştığım biraz ekleme yaptığım kernel.\n",
    "<br>\n",
    "Kaynak = https://www.kaggle.com/burhanykiyakoglu/predicting-house-prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
